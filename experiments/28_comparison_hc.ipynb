{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComparisonHC\n",
    "\n",
    "ComparisonHC is a non-embedding based clustering algorithm based that was develop in [Foundations of Comparison-Based Hierarchical Clustering](https://arxiv.org/abs/1811.00928?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529).\n",
    "\n",
    "As this algorithm does not have any geometric bias, it might be useful to compare to the performance of the Tangles algorithm.\n",
    "\n",
    "We use the passive versions of the algorithm. Essentially, there are two different\n",
    "versions (4-AL and 4K-AL), but they perform mostly similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from cblearn.datasets import fetch_car_similarity\n",
    "from cblearn.preprocessing import triplets_from_mostcentral\n",
    "from itertools import permutations\n",
    "from comparisonhc import ComparisonHC\n",
    "from comparisonhc.oracle import OracleComparisons\n",
    "from comparisonhc.linkage import OrdinalLinkageAverage\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import comparison_hc as chc_est\n",
    "from data_generation import generate_gmm_data_fixed_means\n",
    "from cblearn.datasets import make_random_triplets\n",
    "from triplets import reduce_triplets\n",
    "from estimators import OrdinalTangles\n",
    "from questionnaire import Questionnaire\n",
    "from plotting import AltairPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = fetch_car_similarity()\n",
    "\n",
    "def unify_triplets_mostcentral(triplets, responses) -> np.ndarray:\n",
    "    triplets_unified = []\n",
    "    for t, r in zip(triplets, responses):\n",
    "        a,b,c = t\n",
    "        if r == 0:\n",
    "            t_ = [a,b,c]\n",
    "        elif r == 1:\n",
    "            t_ = [b,c,a]\n",
    "        elif r == 2:\n",
    "            t_ = [c,a,b]\n",
    "        else: \n",
    "            raise ValueError(f\"Response must be 0, 1 or 2, not {r}\")\n",
    "        triplets_unified.append(t_) \n",
    "    res = np.array(triplets_unified)\n",
    "    assert res.shape == triplets.shape\n",
    "    return res\n",
    "\n",
    "# reduce triplets\n",
    "def reduce_triplets_mostcentral(triplets, responses) -> np.ndarray:\n",
    "    unified_triplets = unify_triplets_mostcentral(triplets, responses)\n",
    "    reduced_triplets = []\n",
    "    for t in unified_triplets:\n",
    "        if any(list(t_perm) in reduced_triplets for t_perm in permutations(t)):\n",
    "            # we already added this\n",
    "            continue\n",
    "        a,b,c = t\n",
    "        a_first_mask = np.all(triplets == np.array([a,b,c]), axis=1) | np.all(triplets == np.array([a,c,b]), axis=1)\n",
    "        b_first_mask = np.all(triplets == np.array([b,a,c]), axis=1) | np.all(triplets == np.array([b,c,a]), axis=1)\n",
    "        c_first_mask = np.all(triplets == np.array([c,a,b]), axis=1) | np.all(triplets == np.array([c,b,a]), axis=1)\n",
    "        first_pick = np.argmax([a_first_mask.sum(), b_first_mask.sum(), c_first_mask.sum()])\n",
    "        reduced_triplets.append([t[first_pick], t[(first_pick + 1) % 3], t[(first_pick + 2) % 3]])\n",
    "        \n",
    "    return np.array(reduced_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_reduce_central = reduce_triplets_mostcentral(cars.triplet, cars.response)\n",
    "t = triplets_from_mostcentral(triplets_reduce_central)\n",
    "r = np.ones(t.shape[0]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible UB if triplets have contradictions? ask David\n",
    "# we want to keep consistent behaviour, should we put\n",
    "# comparisonHC into cblearn\n",
    "# t = triplets_from_mostcentral(cars.triplet, cars.response)\n",
    "# r = np.ones(t.shape[0])\n",
    "# mat = check_query_response(t, r, result_format=\"tensor-count\").todense()\n",
    "# print(mat[mat < -1])\n",
    "# print(mat[mat > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets_to_quadruplets(triplets: np.ndarray, responses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transforms an array of triplets (with responses) to an array of quadruplets.\n",
    "\n",
    "    Assumes triplets, responses to be in list-boolean form, e.g. \n",
    "\n",
    "    responses[i] is True if triplets[i][0] is closer to triplets[i][1] than to \n",
    "    triplets[i][2].\n",
    "\n",
    "    If responses is 0, we assume that all responses are true (e.g. it is always triplets[i][1] closer).\n",
    "\n",
    "    We return a quadruplet matrix that is filled according to the following scheme:\n",
    "    If the triplet array allows for a statement (a,b,c) in triplet form then we\n",
    "    set quadruplet[a,b,a,c] = 1 quadruplet[]\n",
    "\n",
    "    Triplets may contain duplicates or conflicting entries.\n",
    "    In this case, we replace the value with a majority vote.\n",
    "    \"\"\"\n",
    "    # error checking\n",
    "    if len(triplets.shape) != 2:\n",
    "        raise ValueError(\"Triplets must be a 2D array\")\n",
    "    if triplets.shape[1] != 3:\n",
    "        raise ValueError(\"Triplets must have 3 columns\")\n",
    "    num_triplets = triplets.shape[0]\n",
    "    if responses is None:\n",
    "        responses = np.ones(num_triplets).astype(bool)\n",
    "    if len(responses.shape) != 1:\n",
    "        raise ValueError(\"Responses must be a 1D array or None\")\n",
    "    n = np.max(triplets) + 1\n",
    "    q = np.zeros((n,n,n,n))\n",
    "\n",
    "    for i in range(num_triplets):\n",
    "        t = triplets[i]\n",
    "        r = responses[i]\n",
    "        if r:\n",
    "            a,b,c = t[0], t[1], t[2]\n",
    "        else:\n",
    "            a,b,c = t[0], t[2], t[1]\n",
    "\n",
    "        if q[a,b,a,c] != 0 or q[a,c,a,b] != 0:\n",
    "            raise ValueError(f\"Unreduced triplets found (or responses): {t, r, i}\")\n",
    "        q[a,b,a,c] = 1\n",
    "        q[a,c,a,b] = -1\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<comparisonhc.core.ComparisonHC at 0x1687a1130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quads = triplets_to_quadruplets(t, r)\n",
    "oracle = OracleComparisons(quads)\n",
    "linkage = OrdinalLinkageAverage(oracle)\n",
    "chc = ComparisonHC(linkage)\n",
    "chc.fit([[i] for i in range(60)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = chc._get_k_clusters(chc.dendrogram, chc.clusters, 4)\n",
    "# sum can essentially be used as a mapReduce / flatMap ;)\n",
    "labels_in_order = sum([[i] * len(cluster) for i, cluster in enumerate(clusters)], [])\n",
    "labels_for_original = [-1] * len(labels_in_order)\n",
    "for lab, pos in zip(labels_in_order, sum(clusters, [])):\n",
    "    labels_for_original[pos] = lab\n",
    "assert -1 not in labels_for_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08906096664821156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(cars.class_id, labels_for_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test comparisonHC on synthetic data (with our provided estimator, to make things easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "data = generate_gmm_data_fixed_means(10, np.array([[1,0], [-1, 0]]), 0.3, seed)\n",
    "chc = chc_est.ComparisonHC(2)\n",
    "t = reduce_triplets(*make_random_triplets(data.xs, result_format=\"list-boolean\", size=5000, random_state=seed))\n",
    "y_chc = chc.fit_predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHC performance: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ba3e035c157d40f5b63017a182010f97\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ba3e035c157d40f5b63017a182010f97\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ba3e035c157d40f5b63017a182010f97\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-2cb786019f6d398bbe1c73c19c329bf0\"}, \"mark\": \"point\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"predicted\", \"scale\": {\"scheme\": \"dark2\"}}, \"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-2cb786019f6d398bbe1c73c19c329bf0\": [{\"x\": 0.9583242152594529, \"y\": -0.0056266827226329474, \"predicted\": 0}, {\"x\": 0.7863803904331546, \"y\": 0.16402708084049888, \"predicted\": 0}, {\"x\": 0.8206564414805136, \"y\": -0.08417473656562041, \"predicted\": 0}, {\"x\": 1.0502881417158043, \"y\": -0.12452880866072316, \"predicted\": 0}, {\"x\": 0.8942047781137661, \"y\": -0.09090076149268494, \"predicted\": 0}, {\"x\": 1.0551454044546424, \"y\": 0.22922080128149577, \"predicted\": 0}, {\"x\": 1.0041539392998404, \"y\": -0.11179254451135168, \"predicted\": 0}, {\"x\": 1.053905832058079, \"y\": -0.0596159699806467, \"predicted\": 0}, {\"x\": 0.9980869503478849, \"y\": 0.11750012195002911, \"predicted\": 0}, {\"x\": 0.9252129050706137, \"y\": 0.0009025250973325124, \"predicted\": 0}, {\"x\": -1.0878107893240343, \"y\": -0.015643417038462365, \"predicted\": 1}, {\"x\": -0.9743429547998704, \"y\": -0.09887790487696219, \"predicted\": 1}, {\"x\": -1.0338821966029197, \"y\": -0.02361840308526013, \"predicted\": 1}, {\"x\": -1.0637655012484302, \"y\": -0.11876122863852843, \"predicted\": 1}, {\"x\": -1.1421217227304128, \"y\": -0.015349519567694914, \"predicted\": 1}, {\"x\": -1.0269056960216014, \"y\": 0.22313667888866046, \"predicted\": 1}, {\"x\": -1.2434767576521044, \"y\": 0.011272650481664892, \"predicted\": 1}, {\"x\": -0.9629555463336765, \"y\": 0.13596338626725962, \"predicted\": 1}, {\"x\": -0.9498142793218687, \"y\": -0.0844213703829862, \"predicted\": 1}, {\"x\": -0.9999990238528403, \"y\": 0.05423525721490291, \"predicted\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"CHC performance: {normalized_mutual_info_score(y_chc, data.ys)}\")\n",
    "p = AltairPlotter()\n",
    "p.assignments(data.xs, y_chc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to Tangles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questionnaire...\n",
      "Generating question set...\n",
      "Filling out questionnaire...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 8422.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangles performance: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q = Questionnaire.from_metric(data.xs, density=0.1)\n",
    "(q.values != -1).size\n",
    "\n",
    "tangles = OrdinalTangles(7)\n",
    "print(f\"Tangles performance: {tangles.score(q.values, data.ys)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3df0bc9139dfbbc2bb43367c6e0b1c6fcd610288dc61cb8c73318fe0a42d151"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tangles-thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
