{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Block Model experiments\n",
    "As we have seen in previous experiments, Tangles do not outperform a simple SOE-kMeans baseline, when applied to euclidean data. This can be expected, as kMeans has a euclidean bias, which could help recover the original data. To see if tangles perform better on non-euclidean data, we will use a stochastic block model (SMB).\n",
    "\n",
    "## Stochastic Block Model\n",
    "An SMB is a graph model. For the simple models we use here, we have that each SMB consists of $k$ clusters with $n$ points each. There exists an edge between two points $v, w$ with probability $p$ if the points are in the same cluster, and an edge with probability $q$ if they are in different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from data_generation import generate_smb_data\n",
    "from estimators import LandmarkTangles, SoeKmeans, OrdinalTangles\n",
    "from questionnaire import Questionnaire\n",
    "from tangles.loading import load_SBM\n",
    "from tangles.cut_finding import kernighan_lin\n",
    "from tangles.cost_functions import mean_edges_cut_cost\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(120384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are providing a function to easily evaluate tangles performance on SMB. We \n",
    "build an SMB, generate triplets from it via shortest path, run the baseline as well as tangles on it, and give back the results averaged over a number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smb_performance(p, q, n=20, k=5, n_runs=1):\n",
    "    \"\"\"\n",
    "    Tests the performance of tangles on an SMB. \n",
    "    Returns the score of the the tangles algorithm and of the baseline (SOE-kMeans) \n",
    "    average over n_runs.\n",
    "    \"\"\"\n",
    "    tangles_scores = []\n",
    "    baseline_scores = []\n",
    "    for _ in range(n_runs):\n",
    "        graph, ys = generate_smb_data(n=n, k=k, p=p, q=q)\n",
    "        questionnaire = Questionnaire.from_graph(graph, density=0.1, verbose=False)\n",
    "\n",
    "        t,r = questionnaire.to_bool_array()\n",
    "\n",
    "        tangles = LandmarkTangles(8, verbose=0)\n",
    "        tangles_labels = tangles.fit_predict(t, r)\n",
    "        tangles_score = normalized_mutual_info_score(ys, tangles_labels)\n",
    "\n",
    "        #\n",
    "        soe_knn = SoeKmeans(2, 5)\n",
    "        baseline_labels = soe_knn.fit_predict(t, r)\n",
    "        baseline_score = normalized_mutual_info_score(ys, baseline_labels)\n",
    "\n",
    "        baseline_scores.append(baseline_score)\n",
    "        tangles_scores.append(tangles_score)\n",
    "\n",
    "    return np.mean(tangles_scores), np.mean(baseline_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smoke test to see if everything runs and has expected results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangles: 0.9347684918528811\n",
      "Baseline: 0.8675564559194765\n"
     ]
    }
   ],
   "source": [
    "tangles_nmi, baseline_nmi = smb_performance(0.9, 0.1)\n",
    "print(f\"Tangles: {tangles_nmi}\\nBaseline: {baseline_nmi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we build a meshgrid over different parameter values and plot it in a heat map. This is similar to what [Solveig did in her SMB experiments](https://arxiv.org/abs/2006.14444) (but there she used [Kernighan-Lin](https://en.wikipedia.org/wiki/Kernighanâ€“Lin_algorithm) to find cuts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vt/mjwkbpzn6js11dz_sdspkzxw0000gn/T/ipykernel_24340/3314398991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnmi_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmb_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtangles_nmi_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmi_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbaseline_nmi_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vt/mjwkbpzn6js11dz_sdspkzxw0000gn/T/ipykernel_24340/2955974670.py\u001b[0m in \u001b[0;36msmb_performance\u001b[0;34m(p, q, n, k, n_runs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msoe_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoeKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mbaseline_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoe_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mbaseline_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_mutual_info_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/master-thesis/experiments/../estimators.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, triplets, responses, y)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mPerforms\u001b[0m \u001b[0mSOE\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mkMeans\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kmeans\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_k_silhouette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_k_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/cblearn/embedding/_soe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, init, n_objects)\u001b[0m\n\u001b[1;32m    123\u001b[0m                                     seed=random_state.randint(1))\n\u001b[1;32m    124\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"scipy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             result = minimize(_soe_loss, init.ravel(), args=(init.shape, triplets, self.margin), method='L-BFGS-B',\n\u001b[0m\u001b[1;32m    126\u001b[0m                               jac=True, options=dict(maxiter=self.max_iter, disp=self.verbose))\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/cblearn/embedding/_soe.py\u001b[0m in \u001b[0;36m_soe_loss\u001b[0;34m(x, x_shape, triplets, margin)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mX_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mij_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mkl_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mij_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mij_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mdifferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mij_dist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmargin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkl_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# meshgrid\n",
    "p, q = np.meshgrid(np.arange(0.1, 1.0, 0.1), np.concatenate(\n",
    "    ([0.01], np.arange(0.05, 0.5, 0.05))))\n",
    "\n",
    "tangles_nmi_grid = np.zeros_like(p)\n",
    "baseline_nmi_grid = np.zeros_like(q)\n",
    "for i in range(p.shape[0]):\n",
    "    for j in range(p.shape[1]):\n",
    "        nmi_score, baseline_score = smb_performance(p[i, j], q[i, j])\n",
    "        tangles_nmi_grid[i, j] = nmi_score\n",
    "        baseline_nmi_grid[i, j] = baseline_score\n",
    "\n",
    "tangles_nmi_df = pd.DataFrame(\n",
    "    {'p': p.ravel(), 'q': q.ravel(), 'nmi': tangles_nmi_grid.ravel()})\n",
    "baseline_nmi_df = pd.DataFrame(\n",
    "    {'p': p.ravel(), 'q': q.ravel(), 'nmi': baseline_nmi_grid.ravel()})\n",
    "\n",
    "tangles_chart = alt.Chart(tangles_nmi_df).mark_rect().encode(\n",
    "    x=alt.X('p:O', axis=alt.Axis(title='p', format=\".2\")),\n",
    "    y=alt.Y('q:O', axis=alt.Axis(title='q', format=\".2\"),\n",
    "            sort=alt.EncodingSortField('q', order='descending'),\n",
    "            ),\n",
    "    color='nmi:Q'\n",
    ").properties(title=\"Tangles\").interactive()\n",
    "\n",
    "baseline_chart = alt.Chart(baseline_nmi_df).mark_rect().encode(\n",
    "    x=alt.X('p:O', axis=alt.Axis(title='p', format=\".2\")),\n",
    "    y=alt.Y('q:O', axis=alt.Axis(title='q', format=\".2\"),\n",
    "            sort=alt.EncodingSortField('q', order='descending'),\n",
    "            ),\n",
    "    color='nmi:Q'\n",
    ").properties(title=\"Baseline\").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_chart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vt/mjwkbpzn6js11dz_sdspkzxw0000gn/T/ipykernel_24340/1737728403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mbaseline_chart\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mtangles_chart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_chart' is not defined"
     ]
    }
   ],
   "source": [
    "(baseline_chart | tangles_chart).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results we observe are a bit weird, we would expect Tangles to outperform the baseline. This seems to require further inquiries. We suspect that shortest path length might not be the best candidate, as out-of-cluster connections are quite prevalent, and due to there being just a lot more out-of-cluster nodes than in-cluster nodes, the possibility that a direct connection to an out-of-cluster node is existing is very high.\n",
    "\n",
    "We use a simple MC-estimate to determine inner-path expected length, outer-path expected length and based on that, number of nodes that have an outer-cluster-node as nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inner distance: 1.2550000000000001\n",
      "Average outer distance: 1.705833333333333\n",
      "Average percentage of closest neighbour being outer cluster: 0.93\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "k = 5\n",
    "graph, ys = generate_smb_data(n=n, k=k, p=0.7, q=0.2)\n",
    "paths = nx.floyd_warshall_numpy(graph)\n",
    "\n",
    "inner_dists_list = []\n",
    "outer_dists_list = []\n",
    "num_wrong_neighbour_list = []\n",
    "\n",
    "# average path length\n",
    "for i in range(k):\n",
    "    block_lower, block_upper = (i * n, (i + 1) * n)\n",
    "    current_block_mask = np.ones_like(paths) == 0\n",
    "    current_block_mask[block_lower:block_upper, block_lower:block_upper] = True\n",
    "    inner_dists = paths[current_block_mask]\n",
    "    outer_dists = paths[~current_block_mask]\n",
    "\n",
    "    inner_dists_list.append(inner_dists.mean())\n",
    "    outer_dists_list.append(outer_dists.mean())\n",
    "\n",
    "    current_points = np.copy(paths[block_lower:block_upper, :])\n",
    "    current_points[current_points == 0] = np.inf\n",
    "    nearest_neighbours = np.argmin(current_points, axis=1)\n",
    "    num_wrong_neighbour_list.append(np.sum(np.logical_or(nearest_neighbours <=\n",
    "                                                         block_lower, nearest_neighbours >= block_upper))/n)\n",
    "\n",
    "print(f\"Average inner distance: {np.mean(inner_dists_list)}\")\n",
    "print(f\"Average outer distance: {np.mean(outer_dists_list)}\")\n",
    "print(\n",
    "    f\"Average percentage of closest neighbour being outer cluster: {np.mean(num_wrong_neighbour_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the average inner vs outer distance is different, but not hugely. More concerning however, is the number of nodes with wrong cluster. We cannot expect to achieve any reasonable clustering with that (and it's suspicious that SOE-kMeans performs that well still, this might be due to induced bias, since we tell the algorithm the number of clusters).\n",
    "\n",
    "We also find another peculiarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(num_wrong_neighbour_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all but the first cluster have their closest neighbour in another cluster. This is an artifact of the argmax. When multiple values in an array are the same, argmax always picks the first occurence. Additionally, for all clusters besides the first, there is a very high probability, that there is already a direct neighbour in the first cluster, for example with $q = 0.2$ and $n = 20$:\n",
    "\n",
    "$$1 - (1-q)^n = 1 - 0.8^{20} = 0.0115$$ \n",
    "\n",
    "This causes argmax to almost always pick a random node from the first cluster.\n",
    "We can fix this by providing a different argmin implementation.\n",
    "Additionally, to really get a cluster structure, we need p and q a lot lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inner distance: 1.233\n",
      "Average outer distance: 1.6954999999999998\n",
      "Average percentage of closest neighbour being outer cluster: 0.63\n"
     ]
    }
   ],
   "source": [
    "def rand_argmin(x): \n",
    "    \"\"\"Returns random indices of all elements of x with the smallest value\n",
    "    over axis 1.\"\"\"\n",
    "    out = []\n",
    "    for row in x:\n",
    "        out.append(np.random.choice(np.flatnonzero(row == row.min())))\n",
    "    return np.array(out)\n",
    "\n",
    "n = 20\n",
    "k = 5\n",
    "graph, ys = generate_smb_data(n=n, k=k, p=0.7, q=0.2)\n",
    "paths = nx.floyd_warshall_numpy(graph)\n",
    "\n",
    "inner_dists_list = []\n",
    "outer_dists_list = []\n",
    "num_wrong_neighbour_list = []\n",
    "\n",
    "# average path length\n",
    "for i in range(k):\n",
    "    block_lower, block_upper = (i * n, (i + 1) * n)\n",
    "    current_block_mask = np.ones_like(paths) == 0\n",
    "    current_block_mask[block_lower:block_upper, block_lower:block_upper] = True\n",
    "    inner_dists = paths[current_block_mask]\n",
    "    outer_dists = paths[~current_block_mask]\n",
    "\n",
    "    inner_dists_list.append(inner_dists.mean())\n",
    "    outer_dists_list.append(outer_dists.mean())\n",
    "\n",
    "    current_points = np.copy(paths[block_lower:block_upper, :])\n",
    "    current_points[current_points == 0] = np.inf\n",
    "    nearest_neighbours = rand_argmin(current_points)\n",
    "    num_wrong_neighbour_list.append(np.sum(np.logical_or(nearest_neighbours <=\n",
    "                                                         block_lower, nearest_neighbours >= block_upper))/n)\n",
    "\n",
    "print(f\"Average inner distance: {np.mean(inner_dists_list)}\")\n",
    "print(f\"Average outer distance: {np.mean(outer_dists_list)}\")\n",
    "print(\n",
    "    f\"Average percentage of closest neighbour being outer cluster: {np.mean(num_wrong_neighbour_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangles as graph preprocessing\n",
    "With that knowledge, we will take a look at using Tangles as preprocessing steps on graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tangles_smb_spectral_performance(p, q, n, k):\n",
    "    graph, ys = generate_smb_data(n=n, k=k, p=p, q=q)\n",
    "    questionnaire = Questionnaire.from_graph(graph, density=0.001, verbose=1)\n",
    "\n",
    "    t,r = questionnaire.to_bool_array()\n",
    "\n",
    "    # tangles\n",
    "    tangles = LandmarkTangles(math.ceil(n/3), verbose=0)\n",
    "    nmi = tangles.score(t, r, ys)\n",
    "\n",
    "    # spectral\n",
    "    sc = SpectralClustering(n_clusters=k, affinity='precomputed')\n",
    "    baseline_labels = sc.fit_predict(X = nx.to_numpy_matrix(graph))\n",
    "    baseline_score = normalized_mutual_info_score(ys, baseline_labels)\n",
    "    return nmi, baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questionnaire...\n",
      "Generating question set...\n",
      "Filling out questionnaire...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 2507.15it/s]\n",
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tangles-thesis/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangles_smb_spectral_performance(0.9, 0.1, 500, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplets vs KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, ys, G = load_SBM(block_sizes=[200, 200, 200, 200], p_in=0.7, p_out=0.1, seed=2)\n",
    "cuts = kernighan_lin(A, nb_cuts=20, lb_f=0.1, seed=2, verbose=0, early_stopping=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questionnaire...\n",
      "Generating question set...\n",
      "Filling out questionnaire...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:00<00:00, 3956.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3744572399462906, 0.7745041314990786)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaire = Questionnaire.from_graph(G, density=0.001, verbose=1)\n",
    "\n",
    "t,r = questionnaire.to_bool_array()\n",
    "mean_edges_cost = partial(mean_edges_cut_cost, A, None)\n",
    "\n",
    "# tangles\n",
    "tangles = LandmarkTangles(40, verbose=0, cost_function=mean_edges_cost)\n",
    "nmi = tangles.score(t, r, ys)\n",
    "\n",
    "# with cuts\n",
    "tangles_cuts = OrdinalTangles(40, verbose=0, cost_function=mean_edges_cost)\n",
    "tangles_cuts.fit(cuts.T)\n",
    "nmi_cuts = normalized_mutual_info_score(ys, tangles_cuts.labels_)\n",
    "nmi, nmi_cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When one runs the above code, one can see that Tangles do not outperform simple cuts for \n",
    "preprocessing. \n",
    "\n",
    "The cut quality suffers in the triplet approach (which makes the Tangles clustering run slower). \n",
    "For the same run-time, this requires us to use less triplet cuts (making the clustering less accurate)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3df0bc9139dfbbc2bb43367c6e0b1c6fcd610288dc61cb8c73318fe0a42d151"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tangles-thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
